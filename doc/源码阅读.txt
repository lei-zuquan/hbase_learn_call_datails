源码阅读关键的几个类：
1、HRegionServer.java
2、HRegion.java
3、HStore.java
4、MemStoreFlusher.java
5、HConstants.java
6、HeapMemorySizeUtil.java
7、PeriodicMemstoreFlusher类
8、IncreasingToUpperBoundRegionSplitPolicy

HRegionServer.java
HRegionServer extends HasThread implements RegionServerServices, LastSequenceId {}
--------------------
run()线程运行方法
    preRegistrationInitialization(); // 准备初始化工作
        initializeThreads();
                // 创建刷写数据到文件线程：Cache flushing thread.
                this.cacheFlusher = new MemStoreFlusher(conf, this);
                // 创建合并小文件线程：Compaction thread
                this.compactSplitThread = new CompactSplitThread(this);

    handleReportForDutyResponse(w); // Run init. Sets up wal and starts up all server threads.
        startServiceThreads();
          /*
           * Start maintenance Threads, Server, Worker and lease checker threads.
           * Install an UncaughtExceptionHandler that calls abort of RegionServer if we
           * get an unhandled exception. We cannot set the handler on all threads.
           * Server's internal Listener thread is off limits. For Server, if an OOME, it
           * waits a while then retries. Meantime, a flush or a compaction that tries to
           * run should trigger same critical condition and the shutdown will run. On
           * its way out, this server will shut down Server. Leases are sort of
           * inbetween. It has an internal thread that while it inherits from Chore, it
           * keeps its own internal stop mechanism so needs to be stopped by this
           * hosting server. Worker logs the exception and exits.
           */
            *启动维护线程，服务器，工作线程和检查程序线程。
            *如果我们获得未处理的异常，通过调用UncaughtExceptionHandler来调用RegionServer的异常终止
            *我们不能在所有线程上设置处理程序。服务器的内部侦听器线程已超出限制。
            *对于服务器，如果是OOM，则为等待片刻，然后重试。 同时，尝试刷新或压缩
            *运行应触发相同的临界条件，并且将运行关机。
            *所有方法都尝试完了，此服务器将关闭服务器。
            *租赁有之间。 它具有一个内部线程，尽管它从Chore继承而来，保留自己的内部停止机制，因此需要以此停止
            *托管服务器。 Worker记录异常并退出。

MemStoreFlusher.java
--------------------
    如果MemStore大小超过堆内存的0.4或者超过堆内存的0.38，如果超过堆内存的0.38客户端就不能往里面写数据（进行阻塞），直到低于堆内存的0.38，可以写
    FlushHandler extends HasThread {}
        run()
            flushOneForGlobalPressure()
              /**
               * The memstore across all regions has exceeded the low water mark. Pick
               * one region to flush and flush it synchronously (this is called from the
               * flush thread)
               * @return true if successful
               */
               /**
               所有地区的记忆库都已超过最低水位线。 选择一个区域进行冲洗并同步冲洗（从冲洗线程中调用）
               *如果成功，则返回true
               */

               flushRegion(regionToFlush, true, true);
               / **
                   *冲洗一个区域。
                   * @param region要刷新的区域。
                   * @param EmergencyFlush设置是否强制刷新。 如果为true，则需要从刷新队列中删除该区域。 如果为false，则在主刷新程序运行循环中调用我们时，通过在刷新队列上调用poll（将其删除）来刷新条目。
                   * @param forceFlushAllStores是否要刷新所有存储。
                   * @return如果成功刷新了区域，则返回true，否则返回false。 如果为false，将附带日志消息，说明未刷新该区域的原因。
               */

HRegion.java
----------------
/*
   * Check if resources to support an update.
   *
   * We throw RegionTooBusyException if above memstore limit
   * and expect client to retry using some kind of backoff
  */
  private void checkResources() throws RegionTooBusyException {
    // If catalog region, do not impose resource constraints or block updates.
    if (this.getRegionInfo().isMetaRegion()) return;

    // 当异常超过128 * 4时，会进行刷写请求，同时会往外抛异常告诉业务当前正在忙碌
    if (this.memstoreSize.get() > this.blockingMemStoreSize) {
      blockedRequestsCount.increment();
      requestFlush();
      throw new RegionTooBusyException("Above memstore limit, " +
          "regionName=" + (this.getRegionInfo() == null ? "unknown" :
          this.getRegionInfo().getRegionNameAsString()) +
          ", server=" + (this.getRegionServerServices() == null ? "unknown" :
          this.getRegionServerServices().getServerName()) +
          ", memstoreSize=" + memstoreSize.get() +
          ", blockingMemStoreSize=" + blockingMemStoreSize);
    }
  }

=======================
doMiniBatchMutation
    / **
    * 由给定线程持有的行锁。
    * 一个线程可以同时在同一行上获取多个锁。
    * 必须通过从同一线程调用release（）来释放锁。
    * /
    RowLock rowLock = null; // HBase只支持行级锁，不支持事务。只支持单行单次操作的事务

    // STEP 1. Try to acquire as many locks as we can, and ensure we acquire at least one.
            //步骤1.尝试获取尽可能多的锁，并确保至少获取一个。
    // STEP 2. Update any LATEST_TIMESTAMP timestamps
            //步骤2。更新所有LATEST_TIMESTAMP时间戳
    // STEP 3. Build WAL edit
            //步骤3。建立WAL编辑
    // STEP 4. Append the final edit to WAL. Do not sync wal. // 写数据到WAL中。目前数据在预写日志中进行追加，并没有同步到HFile文件当中
            //步骤4。将最终编辑附加到WAL。 不同步wal。
    // STEP 5. Write back to memstore   // 写数据到MemStore
            //步骤5。写回到memstore
    // Write to memstore. It is ok to write to memstore
    // first without syncing the WAL because we do not roll
    // forward the memstore MVCC. The MVCC will be moved up when
    // the complete operation is done. These changes are not yet
    // visible to scanners till we update the MVCC. The MVCC is
    // moved only when the sync is complete.
             //写入memstore。 可以写信给memstore
             //首先不同步WAL，因为我们不滚动
             //转发记忆库MVCC。 MVCC将在以下时间向上移动
             //完成完整的操作。 这些变化尚未
             //对扫描程序可见，直到我们更新MVCC。 MVCC是
             //仅在同步完成后才移动。

    // STEP 6. Release row locks, etc. // 释放行级锁
             // STEP 6.释放行锁，等等。
    // STEP 7. Sync wal.
            // STEP7。同步wal。
    // STEP 8. Advance mvcc. This will make this put visible to scanners and getters.
            //步骤8。前进mvcc。 这将使扫描器和吸气剂可以看到此放置的内容。
    // STEP 9. Run coprocessor post hooks. This should be done after the wal is synced so that the coprocessor contract is adhered to.
            //步骤9.运行协处理器后钩子。 应该在同步沃尔玛之后执行此操作，以便遵守协处理器合同。
            rollbackMemstore // if the wal sync was unsuccessful, remove keys from memstore

    
1.2.0版本：
重点1：
    哪些情况下HBase会对memStore数据进行刷写：
    条件1：整个 RegionServer 的 MemStore 占用内存总和大于相关阈值。当单个HRegion内所有的MemStore大小总和超过指定值时，默认128M，flush该HRegion的所有memStore。RegionServer的flush是通过将请求添加一个队列，模拟生产消引费
        模型来异步处理的。那这里就有一个问题，当队列来不及消费，产生大量积压请求时，可能会导致内存陡增，最坏的情况是触发OOM。

    条件2：单个region里memstore的缓存大小，超过那么整个HRegion就会flush,默认128M 。 当MemStore使用内存总量达到hbase.regionserver.global.memstore.upperLimit指定值时，将会有多个MemStores flush到文件中，
        MemStore flush 顺序是按照大小降序执行的，直到刷新到MemStore使用内存略小于lowerLimit
            hbase.regionserver.global.memstore.upperLimit: 0.4
            hbase.regionserver.global.memstore.size（新版本），默认0.4
            hbase.regionserver.global.memstore.lowerLimit: 0.95 即：0.4 * 0.95 = 0.38，超过堆内存最大值的0.38，则会阻塞写操作，直到memStore恢复到一个“可管理”的大小
            hbase.regionserver.global.memstore.size.lower.limit(新版本)，默认0.95
            另外：如果memStore大小超过128 * 4 = 512M 时，也会阻塞写入操作；源码位置： HRegion.java --> checkResources()
    条件3：内存中的文件在自动刷新之前能够存活的最长时间，默认是1h；超过存活1h小时，也会进行刷写

    条件4：WAL数量大于相关阈值

    条件5：定期自动刷写，
        如果我们很久没有对 HBase 的数据进行更新，这时候就可以依赖定期刷写策略了。
        RegionServer 在启动的时候会启动一个线程 PeriodicMemStoreFlusher
        每隔 hbase.server.thread.wakefrequency 时间去检查属于这个 RegionServer 的 Region
        有没有超过一定时间都没有刷写，这个时间是由 hbase.regionserver.optionalcacheflushinterval 参数控制的，
        默认是 3600000，也就是1小时会进行一次刷写。如果设定为0，则意味着关闭定时自动刷写。
        为了防止一次性有过多的 MemStore 刷写，定期自动刷写会有 0 ~ 5 分钟的延迟，具体参见 PeriodicMemStoreFlusher 类的实现。

    条件6：数据更新超过一定阈值
        如果 HBase 的某个 Region 更新的很频繁，而且既没有达到自动刷写阀值，也没有达到内存的使用限制，但是内存中的更新数量已经足够多，
        比如超过 hbase.regionserver.flush.per.changes 参数配置，默认为30000000，那么也是会触发刷写的。

    条件7：手动触发刷写

    需要注意的是，以上所有条件触发的刷写操作最后都会检查对应的 HStore 包含的 StoreFiles 文件
    超过 hbase.hstore.blockingStoreFiles 参数配置的个数，默认值是16。如果满足这个条件，
    那么当前刷写会被推迟到 hbase.hstore.blockingWaitTime 参数设置的时间后再刷写。
    在阻塞刷写的同时，HBase 还会请求 Split 或 Compaction 操作。


重点2：注意不同版本的切分策略是不一样的
    源码位置：HRegion.java 中 checkSplit()
    哪些情况下HBase会对region进行拆分
    条件1：
        HStoreFile最大的大小，当某个region的某个列族超过这个大小会进行region拆分，默认10G
        涉及参数：
            hbase.hregion.max.filesize，默认10737418240

    条件2：
        第一回：当合并的数据超过256M 分进行拆分。initialSize = 2 * conf.getLong(HConstants.HREGION_MEMSTORE_FLUSH_SIZE, HTableDescriptor.DEFAULT_MEMSTORE_FLUSH_SIZE);
        第二回：当合并的数据超过256 * 2 * 2 * 2 = 2G大小

    不切分条件：
        当某个HRegionServer上的region到达这个限制时，不会在进行region切分，也就是一个HRegionServer默认最大允许有1000个region



重点3：
    什么时候将delete中的数据进删除？
        hbase删除是通过向hbase添加删除标记来完成的，让client端查询不到该数据；真正删除数据是在合并compact环节中的major compact进行。


重点4：
    什么时候对数据进行合并compact？
        条件1：MemStore刷写后，判断是否compaction
        条件2：CompactionChecker线程，周期轮询


重点5：
    合并起到哪几个作用？
        1、合并文件
        2、清除删除、过期、多余版本的数据
        3、提高读写数据的效率

    合并分为minor compact和major compact，这两种 compact方式的区别：
        1、Minor操作只用来做部分文件的合并操作以及包括minVersion=0并且设置ttl的过期版本清理，不做任何删除数据、多版本数据的清理工作。
        2、Major操作是对Region下的HStore下的所有StoreFile执行合并操作，最终的结果是整理合并出一个文件。

    合并compact 触发时机：
        1、MemStore刷写后，判断是否compaction
        2、CompactionChecker线程，周期轮询


重点6：HBase如何优化？
    内存优化
        垃圾回收优化:CMS, G1(Region）
        JVM启动：-Xms(1/64) –Xmx(1/4)
    Region优化
        预分区
        禁用major合并，手动合并：hbase.hregion.majorcompaction
    客户端优化
        批处理
        Hbase配置优化：
            高可用
            预分区
            RowKey设计
            内存优化
                HBase操作过程中需要大量的内存开销，毕竟Table是可以缓存在内存中的，一般会分配整个可用内存的70%给HBase的Java堆。
                但是不建议分配非常大的堆内存，因为GC过程持续太久会导致RegionServer处于长期不可用状态，一般16~48G内存就可以了，
                如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。
        HDFS优化：
                1．允许在HDFS的文件中追加内容
                2．优化DataNode允许的最大文件打开数
                3．优化延迟高的数据操作的等待时间
                4．优化数据的写入效率
                5．设置RPC监听数量
                6．优化HStore文件大小
                7．优化hbase客户端缓存
                8．指定scan.next扫描HBase所获取的行数
                9．flush、compact、split机制


重点7：HBase支持事务么？
            HBase数据库侧重于海量数据的存储，所以没有事务的概念。
            但是，HBase单纯一条row数据具有原子性，就是同一个row写操作不允许被打断。



重点8：面向高并发写入优化
        优化点：
            保证负载均衡
            保证写入顺畅
            防止小文件过多
            减少不必要的磁盘和网络IO
        预分区：
            参考 "数据怎么存"
            预分region
            禁用split region
            时间戳为key或前缀时，加入额外的分片前缀
            扫描和读取时每个分片都需要进行一次
        wal禁用或延迟
            setDurability(Durability d)
            Durability是wal延迟类型枚举类
            有丢失数据可能
            表属性DEFERRED_LOG_FLUSH (@Deprecated) 和DURABILITY

    ===================================================
    增大memstroe阻塞写入阈值
        新版本：hbase.regionserver.global.memstore.size
        旧版本：hbase.regionserver.global.memstore.upperLimit
        降低写入阻塞风险
    增大hbase.hstore.blockingStoreFiles
        降低写入阻塞风险
    增大memstore flush阈值
        新版本：hbase.regionserver.global.memstore.size.lower.limit
        旧版本：hbase.regionserver.global.memstore.lowerLimit
        增大单次flush出的文件大小
    减少文件数
        小步快倒————降低compaction最小文件数限制、适当提高最大文件数限制
            单次参与文件少
            hbase.hstore.compaction.min
            hbase.hstore.compaction.max
            防止频繁写入导致flush频繁，进而导致文件数过多
        大步慢走————提高compaction最小文件数限制、进一步提高最大文件数限制
            加大单次compaction文件参与数量
        多个region同在一个region server时，提高线程数
            hbase.regionserver.thread.compaction.large
            hbase.regionserver.thread.compaction.small
            hbase.regionserver.thread.compaction.throttle

面向高并发随机读优化
    使用布隆过滤
    防止发生full gc
        防止内存紧张
        合理调整jvm参数
    增大blockcache
        增加缓存
        hfile.block.cache.size
    使用bucketcache
        使用ssd磁盘作为二级缓存
        0.98开始支持
    减少BLOCKSIZE
        减少data block中的数据
        增加索引，减少平均查找长度
        降低缓存置换成本
        减少特理层读放大


合理控制region数量
    合理分担scan、get、put到每个region server
        对于一个表每个region server上的region数过多无益
        每个region中的数据量最好近似
        region数合理后禁用用split region
            将 MAX_FILESIZE调整为较大值
        合理预分region
            使用hbase shell中的 NUMREGIONS 与 SPLITALGO
            更加灵活可使用HBaseAdmin.createTable(HTableDescripter, byte[][])
                第二个参数指定分割region的split key
            最好一步到位，预分后禁用split region
            推荐
                考虑合理的集群扩展
                每个region server 5个region

























    